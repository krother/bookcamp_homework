{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.10 Homework\n",
    "\n",
    "The goal of this homework is to create a tree-based regression model for prediction apartment prices (column `'price'`).\n",
    "\n",
    "In this homework we'll again use the New York City Airbnb Open Data dataset - the same one we used in homework 2 and 3.\n",
    "\n",
    "You can take it from [Kaggle](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv)\n",
    "or download from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv)\n",
    "if you don't want to sign up to Kaggle.\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'neighbourhood_group', 'room_type', 'latitude', 'longitude',\n",
    "    'minimum_nights', 'number_of_reviews','reviews_per_month',\n",
    "    'calculated_host_listings_count', 'availability_365',\n",
    "    'price'\n",
    "]\n",
    "\n",
    "df = pd.read_csv('AB_NYC.csv', usecols=columns)\n",
    "df.reviews_per_month = df.reviews_per_month.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood_group  latitude  longitude        room_type  price  \\\n",
       "0            Brooklyn  40.64749  -73.97237     Private room    149   \n",
       "1           Manhattan  40.75362  -73.98377  Entire home/apt    225   \n",
       "2           Manhattan  40.80902  -73.94190     Private room    150   \n",
       "\n",
       "   minimum_nights  number_of_reviews  reviews_per_month  \\\n",
       "0               1                  9               0.21   \n",
       "1               1                 45               0.38   \n",
       "2               3                  0               0.00   \n",
       "\n",
       "   calculated_host_listings_count  availability_365  \n",
       "0                               6               365  \n",
       "1                               2               355  \n",
       "2                               1               365  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply the log tranform to `price`\n",
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['neighbourhood_group', 'latitude', 'longitude', 'room_type',\n",
    "       'minimum_nights', 'number_of_reviews', 'reviews_per_month',\n",
    "       'calculated_host_listings_count', 'availability_365']]\n",
    "y = np.log1p(df['price'])\n",
    "\n",
    "Xtv, Xtest, ytv, ytest = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(Xtv, ytv, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use `DictVectorizer` to turn train and validation into matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31292, 15), (7824, 15))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = DictVectorizer()\n",
    "dtrain = Xtrain.to_dict(orient='records')\n",
    "dval = Xval.to_dict(orient='records')\n",
    "dv.fit(dtrain)\n",
    "XT = dv.transform(dtrain)\n",
    "XV = dv.transform(dval)\n",
    "XT.shape, XV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the price variable. \n",
    "\n",
    "* Train a model with `max_depth=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DecisionTreeRegressor(max_depth=1)\n",
    "m.fit(XT,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(167.4, 163.07999999999998, 'room_type=Entire home/apt <= 0.5\\nmse = 0.486\\nsamples = 31292\\nvalue = 4.738'),\n",
       " Text(83.7, 54.360000000000014, 'mse = 0.281\\nsamples = 14991\\nvalue = 4.291'),\n",
       " Text(251.10000000000002, 54.360000000000014, 'mse = 0.32\\nsamples = 16301\\nvalue = 5.15')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tree(m, feature_names=dv.feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which feature is used for splitting the data?\n",
    "\n",
    "* `room_type`\n",
    "* `neighbourhood_group`\n",
    "* `number_of_reviews`\n",
    "* `reviews_per_month`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1`  (optional - to make training faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(XT, ytrain, XV, yval, ntrees=10, maxdep=None):\n",
    "    m = RandomForestRegressor(n_estimators=ntrees, random_state=1, n_jobs=-1, max_depth=maxdep)\n",
    "    m.fit(XT, ytrain)\n",
    "    ypred = m.predict(XT)\n",
    "    train_rmse = np.mean((ytrain.values - ypred)**2) ** 0.5\n",
    "\n",
    "    ypred = m.predict(XV)\n",
    "    val_rmse = np.mean((yval.values - ypred)**2) ** 0.5\n",
    "    return train_rmse, val_rmse, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1944774304539324,\n",
       " 0.4591315921621722,\n",
       " RandomForestRegressor(n_estimators=10, n_jobs=-1, random_state=1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rf(XT, ytrain, XV, yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the RMSE of this model on validation?\n",
    "\n",
    "* 0.059\n",
    "* 0.259\n",
    "* 0.459\n",
    "* 0.659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10\n",
    "* Set `random_state` to `1`\n",
    "* Evaluate the model on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.4591315921621722\n",
      "20 0.44891298190153706\n",
      "30 0.4439177582773954\n",
      "40 0.4419269857629046\n",
      "50 0.4412182050450951\n",
      "60 0.4404691535276386\n",
      "70 0.4398259382571694\n",
      "80 0.4392948885748322\n",
      "90 0.4390771325419698\n",
      "100 0.4387105651457843\n",
      "110 0.43840069391913644\n",
      "120 0.43810007427132325\n",
      "130 0.43773463740383456\n",
      "140 0.4375433086352419\n",
      "150 0.4375637519553974\n",
      "160 0.43750525743449453\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cdd49585f543>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mntrees\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_rf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-3f72198d1858>\u001b[0m in \u001b[0;36mtrain_rf\u001b[0;34m(XT, ytrain, XV, yval, ntrees, maxdep)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_rf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxdep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxdep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ntrees in range(10, 201, 10):\n",
    "    rtrain, rval, m = train_rf(XT, ytrain, XV, yval, ntrees)\n",
    "    print(ntrees, rval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "\n",
    "- 10\n",
    "- 50\n",
    "- 70\n",
    "- 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values, try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "* Fix the random seed: `random_state=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.4394625350145503\n",
      "15 0.43509011936328806\n",
      "20 0.4361913964014386\n",
      "25 0.43713129061501815\n"
     ]
    }
   ],
   "source": [
    "for maxdep in [10, 15, 20, 25]:\n",
    "    best_score = 999999999999999.9\n",
    "    for ntrees in range(10, 201, 10):\n",
    "        rtrain, rval, m = train_rf(XT, ytrain, XV, yval, ntrees, maxdep)\n",
    "        if rval < best_score:\n",
    "            best_score = rval\n",
    "    print(maxdep, rval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the best `max_depth`:\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25\n",
    "\n",
    "Bonus question (not graded):\n",
    "\n",
    "Will the answer be different if we change the seed for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorith, it finds the best split. \n",
    "When doint it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the imporatant features \n",
    "for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the `feature_importances_` field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parametes:\n",
    "    * `n_estimators=10`,\n",
    "    * `max_depth=20`,\n",
    "    * `random_state=1`,\n",
    "    * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('availability_365', 0.07561198057586682),\n",
      " ('calculated_host_listings_count', 0.030444740115403567),\n",
      " ('latitude', 0.1470563392412613),\n",
      " ('longitude', 0.15721924572066343),\n",
      " ('minimum_nights', 0.05358689751255126),\n",
      " ('neighbourhood_group=Bronx', 0.00031849238243457606),\n",
      " ('neighbourhood_group=Brooklyn', 0.0008913259752591024),\n",
      " ('neighbourhood_group=Manhattan', 0.03500253831561246),\n",
      " ('neighbourhood_group=Queens', 0.0011945822324246794),\n",
      " ('neighbourhood_group=Staten Island', 0.00011465377520570967),\n",
      " ('number_of_reviews', 0.04437176031301412),\n",
      " ('reviews_per_month', 0.05254889131106728),\n",
      " ('room_type=Entire home/apt', 0.3925596969487723),\n",
      " ('room_type=Private room', 0.0049920170633734285),\n",
      " ('room_type=Shared room', 0.00408683851709001)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "_,_,m = train_rf(XT, ytrain, XV, yval, ntrees=10, maxdep=20)\n",
    "pprint(list(zip(dv.feature_names_, m.feature_importances_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the most important feature? \n",
    "\n",
    "* `neighbourhood_group=Manhattan`\n",
    "* `room_type=Entire home/apt`\t\n",
    "* `longitude`\n",
    "* `latitude`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 166.7 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/kristian/.local/lib/python3.8/site-packages (from xgboost) (1.5.4)\n",
      "Requirement already satisfied: numpy in /home/kristian/.local/lib/python3.8/site-packages (from xgboost) (1.19.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.4.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(XT, label=ytrain, feature_names=dv.feature_names_)\n",
    "dval = xgb.DMatrix(XV, label=yval, feature_names=dv.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3.02703\tval-rmse:3.02557\n",
      "[1]\ttrain-rmse:2.14613\tval-rmse:2.14509\n",
      "[2]\ttrain-rmse:1.53862\tval-rmse:1.53827\n",
      "[3]\ttrain-rmse:1.12540\tval-rmse:1.12612\n",
      "[4]\ttrain-rmse:0.85055\tval-rmse:0.85292\n",
      "[5]\ttrain-rmse:0.67431\tval-rmse:0.67813\n",
      "[6]\ttrain-rmse:0.56675\tval-rmse:0.57296\n",
      "[7]\ttrain-rmse:0.50401\tval-rmse:0.51231\n",
      "[8]\ttrain-rmse:0.46948\tval-rmse:0.47911\n",
      "[9]\ttrain-rmse:0.45044\tval-rmse:0.46159\n",
      "[10]\ttrain-rmse:0.43985\tval-rmse:0.45201\n",
      "[11]\ttrain-rmse:0.43278\tval-rmse:0.44717\n",
      "[12]\ttrain-rmse:0.42899\tval-rmse:0.44410\n",
      "[13]\ttrain-rmse:0.42636\tval-rmse:0.44219\n",
      "[14]\ttrain-rmse:0.42369\tval-rmse:0.44090\n",
      "[15]\ttrain-rmse:0.42215\tval-rmse:0.44048\n",
      "[16]\ttrain-rmse:0.42041\tval-rmse:0.44004\n",
      "[17]\ttrain-rmse:0.41946\tval-rmse:0.43961\n",
      "[18]\ttrain-rmse:0.41825\tval-rmse:0.43975\n",
      "[19]\ttrain-rmse:0.41627\tval-rmse:0.43923\n",
      "[20]\ttrain-rmse:0.41479\tval-rmse:0.43897\n",
      "[21]\ttrain-rmse:0.41335\tval-rmse:0.43922\n",
      "[22]\ttrain-rmse:0.41285\tval-rmse:0.43907\n",
      "[23]\ttrain-rmse:0.41216\tval-rmse:0.43909\n",
      "[24]\ttrain-rmse:0.41043\tval-rmse:0.43914\n",
      "[25]\ttrain-rmse:0.40974\tval-rmse:0.43915\n",
      "[26]\ttrain-rmse:0.40908\tval-rmse:0.43933\n",
      "[27]\ttrain-rmse:0.40780\tval-rmse:0.43920\n",
      "[28]\ttrain-rmse:0.40710\tval-rmse:0.43880\n",
      "[29]\ttrain-rmse:0.40663\tval-rmse:0.43867\n",
      "[30]\ttrain-rmse:0.40647\tval-rmse:0.43867\n",
      "[31]\ttrain-rmse:0.40625\tval-rmse:0.43862\n",
      "[32]\ttrain-rmse:0.40506\tval-rmse:0.43860\n",
      "[33]\ttrain-rmse:0.40418\tval-rmse:0.43856\n",
      "[34]\ttrain-rmse:0.40390\tval-rmse:0.43854\n",
      "[35]\ttrain-rmse:0.40271\tval-rmse:0.43817\n",
      "[36]\ttrain-rmse:0.40191\tval-rmse:0.43801\n",
      "[37]\ttrain-rmse:0.40094\tval-rmse:0.43770\n",
      "[38]\ttrain-rmse:0.40016\tval-rmse:0.43795\n",
      "[39]\ttrain-rmse:0.39924\tval-rmse:0.43740\n",
      "[40]\ttrain-rmse:0.39886\tval-rmse:0.43733\n",
      "[41]\ttrain-rmse:0.39768\tval-rmse:0.43693\n",
      "[42]\ttrain-rmse:0.39649\tval-rmse:0.43677\n",
      "[43]\ttrain-rmse:0.39549\tval-rmse:0.43687\n",
      "[44]\ttrain-rmse:0.39536\tval-rmse:0.43688\n",
      "[45]\ttrain-rmse:0.39484\tval-rmse:0.43699\n",
      "[46]\ttrain-rmse:0.39446\tval-rmse:0.43700\n",
      "[47]\ttrain-rmse:0.39404\tval-rmse:0.43695\n",
      "[48]\ttrain-rmse:0.39328\tval-rmse:0.43699\n",
      "[49]\ttrain-rmse:0.39300\tval-rmse:0.43728\n",
      "[50]\ttrain-rmse:0.39283\tval-rmse:0.43734\n",
      "[51]\ttrain-rmse:0.39277\tval-rmse:0.43736\n",
      "[52]\ttrain-rmse:0.39195\tval-rmse:0.43763\n",
      "[53]\ttrain-rmse:0.39171\tval-rmse:0.43758\n",
      "[54]\ttrain-rmse:0.39101\tval-rmse:0.43785\n",
      "[55]\ttrain-rmse:0.38981\tval-rmse:0.43765\n",
      "[56]\ttrain-rmse:0.38934\tval-rmse:0.43764\n",
      "[57]\ttrain-rmse:0.38916\tval-rmse:0.43766\n",
      "[58]\ttrain-rmse:0.38816\tval-rmse:0.43753\n",
      "[59]\ttrain-rmse:0.38787\tval-rmse:0.43742\n",
      "[60]\ttrain-rmse:0.38735\tval-rmse:0.43758\n",
      "[61]\ttrain-rmse:0.38702\tval-rmse:0.43768\n",
      "[62]\ttrain-rmse:0.38635\tval-rmse:0.43766\n",
      "[63]\ttrain-rmse:0.38546\tval-rmse:0.43742\n",
      "[64]\ttrain-rmse:0.38525\tval-rmse:0.43744\n",
      "[65]\ttrain-rmse:0.38445\tval-rmse:0.43733\n",
      "[66]\ttrain-rmse:0.38415\tval-rmse:0.43752\n",
      "[67]\ttrain-rmse:0.38398\tval-rmse:0.43756\n",
      "[68]\ttrain-rmse:0.38258\tval-rmse:0.43701\n",
      "[69]\ttrain-rmse:0.38208\tval-rmse:0.43717\n",
      "[70]\ttrain-rmse:0.38157\tval-rmse:0.43712\n",
      "[71]\ttrain-rmse:0.38150\tval-rmse:0.43711\n",
      "[72]\ttrain-rmse:0.38146\tval-rmse:0.43717\n",
      "[73]\ttrain-rmse:0.38121\tval-rmse:0.43725\n",
      "[74]\ttrain-rmse:0.38038\tval-rmse:0.43733\n",
      "[75]\ttrain-rmse:0.37956\tval-rmse:0.43737\n",
      "[76]\ttrain-rmse:0.37880\tval-rmse:0.43755\n",
      "[77]\ttrain-rmse:0.37777\tval-rmse:0.43764\n",
      "[78]\ttrain-rmse:0.37693\tval-rmse:0.43796\n",
      "[79]\ttrain-rmse:0.37614\tval-rmse:0.43794\n",
      "[80]\ttrain-rmse:0.37542\tval-rmse:0.43784\n",
      "[81]\ttrain-rmse:0.37514\tval-rmse:0.43781\n",
      "[82]\ttrain-rmse:0.37437\tval-rmse:0.43786\n",
      "[83]\ttrain-rmse:0.37412\tval-rmse:0.43790\n",
      "[84]\ttrain-rmse:0.37398\tval-rmse:0.43785\n",
      "[85]\ttrain-rmse:0.37362\tval-rmse:0.43782\n",
      "[86]\ttrain-rmse:0.37321\tval-rmse:0.43798\n",
      "[87]\ttrain-rmse:0.37269\tval-rmse:0.43788\n",
      "[88]\ttrain-rmse:0.37256\tval-rmse:0.43794\n",
      "[89]\ttrain-rmse:0.37165\tval-rmse:0.43790\n",
      "[90]\ttrain-rmse:0.37120\tval-rmse:0.43795\n",
      "[91]\ttrain-rmse:0.37055\tval-rmse:0.43788\n",
      "[92]\ttrain-rmse:0.37038\tval-rmse:0.43775\n",
      "[93]\ttrain-rmse:0.37022\tval-rmse:0.43776\n",
      "[94]\ttrain-rmse:0.36998\tval-rmse:0.43766\n",
      "[95]\ttrain-rmse:0.36976\tval-rmse:0.43761\n",
      "[96]\ttrain-rmse:0.36909\tval-rmse:0.43737\n",
      "[97]\ttrain-rmse:0.36835\tval-rmse:0.43735\n",
      "[98]\ttrain-rmse:0.36793\tval-rmse:0.43730\n",
      "[99]\ttrain-rmse:0.36756\tval-rmse:0.43724\n",
      "\n",
      "[0]\ttrain-rmse:3.87166\tval-rmse:3.87023\n",
      "[1]\ttrain-rmse:3.49100\tval-rmse:3.48943\n",
      "[2]\ttrain-rmse:3.14898\tval-rmse:3.14727\n",
      "[3]\ttrain-rmse:2.84180\tval-rmse:2.84019\n",
      "[4]\ttrain-rmse:2.56602\tval-rmse:2.56456\n",
      "[5]\ttrain-rmse:2.31855\tval-rmse:2.31741\n",
      "[6]\ttrain-rmse:2.09664\tval-rmse:2.09553\n",
      "[7]\ttrain-rmse:1.89783\tval-rmse:1.89687\n",
      "[8]\ttrain-rmse:1.71990\tval-rmse:1.71921\n",
      "[9]\ttrain-rmse:1.56081\tval-rmse:1.56028\n",
      "[10]\ttrain-rmse:1.41865\tval-rmse:1.41831\n",
      "[11]\ttrain-rmse:1.29195\tval-rmse:1.29177\n",
      "[12]\ttrain-rmse:1.17926\tval-rmse:1.17927\n",
      "[13]\ttrain-rmse:1.07931\tval-rmse:1.07974\n",
      "[14]\ttrain-rmse:0.99068\tval-rmse:0.99147\n",
      "[15]\ttrain-rmse:0.91253\tval-rmse:0.91363\n",
      "[16]\ttrain-rmse:0.84369\tval-rmse:0.84516\n",
      "[17]\ttrain-rmse:0.78345\tval-rmse:0.78538\n",
      "[18]\ttrain-rmse:0.73084\tval-rmse:0.73319\n",
      "[19]\ttrain-rmse:0.68483\tval-rmse:0.68791\n",
      "[20]\ttrain-rmse:0.64525\tval-rmse:0.64899\n",
      "[21]\ttrain-rmse:0.61100\tval-rmse:0.61536\n",
      "[22]\ttrain-rmse:0.58162\tval-rmse:0.58670\n",
      "[23]\ttrain-rmse:0.55669\tval-rmse:0.56236\n",
      "[24]\ttrain-rmse:0.53532\tval-rmse:0.54185\n",
      "[25]\ttrain-rmse:0.51724\tval-rmse:0.52463\n",
      "[26]\ttrain-rmse:0.50195\tval-rmse:0.51004\n",
      "[27]\ttrain-rmse:0.48925\tval-rmse:0.49796\n",
      "[28]\ttrain-rmse:0.47851\tval-rmse:0.48783\n",
      "[29]\ttrain-rmse:0.46938\tval-rmse:0.47915\n",
      "[30]\ttrain-rmse:0.46183\tval-rmse:0.47202\n",
      "[31]\ttrain-rmse:0.45567\tval-rmse:0.46622\n",
      "[32]\ttrain-rmse:0.45008\tval-rmse:0.46140\n",
      "[33]\ttrain-rmse:0.44560\tval-rmse:0.45746\n",
      "[34]\ttrain-rmse:0.44185\tval-rmse:0.45415\n",
      "[35]\ttrain-rmse:0.43875\tval-rmse:0.45146\n",
      "[36]\ttrain-rmse:0.43594\tval-rmse:0.44922\n",
      "[37]\ttrain-rmse:0.43373\tval-rmse:0.44716\n",
      "[38]\ttrain-rmse:0.43155\tval-rmse:0.44543\n",
      "[39]\ttrain-rmse:0.42993\tval-rmse:0.44417\n",
      "[40]\ttrain-rmse:0.42865\tval-rmse:0.44305\n",
      "[41]\ttrain-rmse:0.42715\tval-rmse:0.44224\n",
      "[42]\ttrain-rmse:0.42603\tval-rmse:0.44155\n",
      "[43]\ttrain-rmse:0.42480\tval-rmse:0.44076\n",
      "[44]\ttrain-rmse:0.42378\tval-rmse:0.43998\n",
      "[45]\ttrain-rmse:0.42274\tval-rmse:0.43932\n",
      "[46]\ttrain-rmse:0.42207\tval-rmse:0.43895\n",
      "[47]\ttrain-rmse:0.42114\tval-rmse:0.43849\n",
      "[48]\ttrain-rmse:0.42023\tval-rmse:0.43822\n",
      "[49]\ttrain-rmse:0.41967\tval-rmse:0.43790\n",
      "[50]\ttrain-rmse:0.41896\tval-rmse:0.43757\n",
      "[51]\ttrain-rmse:0.41844\tval-rmse:0.43732\n",
      "[52]\ttrain-rmse:0.41802\tval-rmse:0.43707\n",
      "[53]\ttrain-rmse:0.41760\tval-rmse:0.43693\n",
      "[54]\ttrain-rmse:0.41711\tval-rmse:0.43668\n",
      "[55]\ttrain-rmse:0.41676\tval-rmse:0.43645\n",
      "[56]\ttrain-rmse:0.41631\tval-rmse:0.43630\n",
      "[57]\ttrain-rmse:0.41590\tval-rmse:0.43622\n",
      "[58]\ttrain-rmse:0.41534\tval-rmse:0.43614\n",
      "[59]\ttrain-rmse:0.41505\tval-rmse:0.43609\n",
      "[60]\ttrain-rmse:0.41492\tval-rmse:0.43612\n",
      "[61]\ttrain-rmse:0.41439\tval-rmse:0.43614\n",
      "[62]\ttrain-rmse:0.41414\tval-rmse:0.43608\n",
      "[63]\ttrain-rmse:0.41373\tval-rmse:0.43587\n",
      "[64]\ttrain-rmse:0.41362\tval-rmse:0.43584\n",
      "[65]\ttrain-rmse:0.41329\tval-rmse:0.43574\n",
      "[66]\ttrain-rmse:0.41319\tval-rmse:0.43576\n",
      "[67]\ttrain-rmse:0.41265\tval-rmse:0.43563\n",
      "[68]\ttrain-rmse:0.41246\tval-rmse:0.43565\n",
      "[69]\ttrain-rmse:0.41205\tval-rmse:0.43562\n",
      "[70]\ttrain-rmse:0.41158\tval-rmse:0.43545\n",
      "[71]\ttrain-rmse:0.41140\tval-rmse:0.43545\n",
      "[72]\ttrain-rmse:0.41112\tval-rmse:0.43538\n",
      "[73]\ttrain-rmse:0.41075\tval-rmse:0.43537\n",
      "[74]\ttrain-rmse:0.41059\tval-rmse:0.43544\n",
      "[75]\ttrain-rmse:0.41018\tval-rmse:0.43533\n",
      "[76]\ttrain-rmse:0.40974\tval-rmse:0.43526\n",
      "[77]\ttrain-rmse:0.40949\tval-rmse:0.43524\n",
      "[78]\ttrain-rmse:0.40927\tval-rmse:0.43528\n",
      "[79]\ttrain-rmse:0.40894\tval-rmse:0.43514\n",
      "[80]\ttrain-rmse:0.40876\tval-rmse:0.43517\n",
      "[81]\ttrain-rmse:0.40854\tval-rmse:0.43511\n",
      "[82]\ttrain-rmse:0.40829\tval-rmse:0.43517\n",
      "[83]\ttrain-rmse:0.40783\tval-rmse:0.43495\n",
      "[84]\ttrain-rmse:0.40775\tval-rmse:0.43495\n",
      "[85]\ttrain-rmse:0.40747\tval-rmse:0.43483\n",
      "[86]\ttrain-rmse:0.40736\tval-rmse:0.43484\n",
      "[87]\ttrain-rmse:0.40715\tval-rmse:0.43475\n",
      "[88]\ttrain-rmse:0.40688\tval-rmse:0.43476\n",
      "[89]\ttrain-rmse:0.40661\tval-rmse:0.43477\n",
      "[90]\ttrain-rmse:0.40656\tval-rmse:0.43480\n",
      "[91]\ttrain-rmse:0.40613\tval-rmse:0.43480\n",
      "[92]\ttrain-rmse:0.40595\tval-rmse:0.43481\n",
      "[93]\ttrain-rmse:0.40585\tval-rmse:0.43473\n",
      "[94]\ttrain-rmse:0.40575\tval-rmse:0.43476\n",
      "[95]\ttrain-rmse:0.40556\tval-rmse:0.43481\n",
      "[96]\ttrain-rmse:0.40551\tval-rmse:0.43482\n",
      "[97]\ttrain-rmse:0.40532\tval-rmse:0.43474\n",
      "[98]\ttrain-rmse:0.40507\tval-rmse:0.43472\n",
      "[99]\ttrain-rmse:0.40467\tval-rmse:0.43459\n",
      "\n",
      "[0]\ttrain-rmse:4.25284\tval-rmse:4.25141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:4.21088\tval-rmse:4.20945\n",
      "[2]\ttrain-rmse:4.16935\tval-rmse:4.16791\n",
      "[3]\ttrain-rmse:4.12824\tval-rmse:4.12680\n",
      "[4]\ttrain-rmse:4.08756\tval-rmse:4.08610\n",
      "[5]\ttrain-rmse:4.04727\tval-rmse:4.04582\n",
      "[6]\ttrain-rmse:4.00740\tval-rmse:4.00595\n",
      "[7]\ttrain-rmse:3.96793\tval-rmse:3.96648\n",
      "[8]\ttrain-rmse:3.92886\tval-rmse:3.92741\n",
      "[9]\ttrain-rmse:3.89019\tval-rmse:3.88874\n",
      "[10]\ttrain-rmse:3.85191\tval-rmse:3.85046\n",
      "[11]\ttrain-rmse:3.81401\tval-rmse:3.81256\n",
      "[12]\ttrain-rmse:3.77650\tval-rmse:3.77504\n",
      "[13]\ttrain-rmse:3.73938\tval-rmse:3.73791\n",
      "[14]\ttrain-rmse:3.70262\tval-rmse:3.70115\n",
      "[15]\ttrain-rmse:3.66624\tval-rmse:3.66475\n",
      "[16]\ttrain-rmse:3.63023\tval-rmse:3.62875\n",
      "[17]\ttrain-rmse:3.59458\tval-rmse:3.59310\n",
      "[18]\ttrain-rmse:3.55930\tval-rmse:3.55781\n",
      "[19]\ttrain-rmse:3.52437\tval-rmse:3.52289\n",
      "[20]\ttrain-rmse:3.48980\tval-rmse:3.48831\n",
      "[21]\ttrain-rmse:3.45558\tval-rmse:3.45408\n",
      "[22]\ttrain-rmse:3.42170\tval-rmse:3.42020\n",
      "[23]\ttrain-rmse:3.38817\tval-rmse:3.38667\n",
      "[24]\ttrain-rmse:3.35498\tval-rmse:3.35346\n",
      "[25]\ttrain-rmse:3.32213\tval-rmse:3.32060\n",
      "[26]\ttrain-rmse:3.28961\tval-rmse:3.28806\n",
      "[27]\ttrain-rmse:3.25743\tval-rmse:3.25588\n",
      "[28]\ttrain-rmse:3.22557\tval-rmse:3.22403\n",
      "[29]\ttrain-rmse:3.19404\tval-rmse:3.19249\n",
      "[30]\ttrain-rmse:3.16283\tval-rmse:3.16127\n",
      "[31]\ttrain-rmse:3.13193\tval-rmse:3.13036\n",
      "[32]\ttrain-rmse:3.10135\tval-rmse:3.09978\n",
      "[33]\ttrain-rmse:3.07108\tval-rmse:3.06950\n",
      "[34]\ttrain-rmse:3.04113\tval-rmse:3.03955\n",
      "[35]\ttrain-rmse:3.01147\tval-rmse:3.00991\n",
      "[36]\ttrain-rmse:2.98212\tval-rmse:2.98057\n",
      "[37]\ttrain-rmse:2.95307\tval-rmse:2.95153\n",
      "[38]\ttrain-rmse:2.92431\tval-rmse:2.92281\n",
      "[39]\ttrain-rmse:2.89586\tval-rmse:2.89437\n",
      "[40]\ttrain-rmse:2.86768\tval-rmse:2.86624\n",
      "[41]\ttrain-rmse:2.83981\tval-rmse:2.83837\n",
      "[42]\ttrain-rmse:2.81221\tval-rmse:2.81081\n",
      "[43]\ttrain-rmse:2.78490\tval-rmse:2.78351\n",
      "[44]\ttrain-rmse:2.75786\tval-rmse:2.75651\n",
      "[45]\ttrain-rmse:2.73110\tval-rmse:2.72979\n",
      "[46]\ttrain-rmse:2.70462\tval-rmse:2.70332\n",
      "[47]\ttrain-rmse:2.67841\tval-rmse:2.67713\n",
      "[48]\ttrain-rmse:2.65247\tval-rmse:2.65121\n",
      "[49]\ttrain-rmse:2.62679\tval-rmse:2.62555\n",
      "[50]\ttrain-rmse:2.60138\tval-rmse:2.60017\n",
      "[51]\ttrain-rmse:2.57623\tval-rmse:2.57503\n",
      "[52]\ttrain-rmse:2.55133\tval-rmse:2.55017\n",
      "[53]\ttrain-rmse:2.52670\tval-rmse:2.52555\n",
      "[54]\ttrain-rmse:2.50232\tval-rmse:2.50118\n",
      "[55]\ttrain-rmse:2.47819\tval-rmse:2.47707\n",
      "[56]\ttrain-rmse:2.45431\tval-rmse:2.45322\n",
      "[57]\ttrain-rmse:2.43067\tval-rmse:2.42960\n",
      "[58]\ttrain-rmse:2.40728\tval-rmse:2.40623\n",
      "[59]\ttrain-rmse:2.38413\tval-rmse:2.38309\n",
      "[60]\ttrain-rmse:2.36122\tval-rmse:2.36019\n",
      "[61]\ttrain-rmse:2.33854\tval-rmse:2.33753\n",
      "[62]\ttrain-rmse:2.31610\tval-rmse:2.31512\n",
      "[63]\ttrain-rmse:2.29389\tval-rmse:2.29293\n",
      "[64]\ttrain-rmse:2.27191\tval-rmse:2.27099\n",
      "[65]\ttrain-rmse:2.25016\tval-rmse:2.24925\n",
      "[66]\ttrain-rmse:2.22864\tval-rmse:2.22775\n",
      "[67]\ttrain-rmse:2.20734\tval-rmse:2.20647\n",
      "[68]\ttrain-rmse:2.18626\tval-rmse:2.18540\n",
      "[69]\ttrain-rmse:2.16539\tval-rmse:2.16456\n",
      "[70]\ttrain-rmse:2.14475\tval-rmse:2.14394\n",
      "[71]\ttrain-rmse:2.12432\tval-rmse:2.12353\n",
      "[72]\ttrain-rmse:2.10410\tval-rmse:2.10331\n",
      "[73]\ttrain-rmse:2.08409\tval-rmse:2.08332\n",
      "[74]\ttrain-rmse:2.06429\tval-rmse:2.06354\n",
      "[75]\ttrain-rmse:2.04470\tval-rmse:2.04397\n",
      "[76]\ttrain-rmse:2.02531\tval-rmse:2.02460\n",
      "[77]\ttrain-rmse:2.00613\tval-rmse:2.00543\n",
      "[78]\ttrain-rmse:1.98715\tval-rmse:1.98647\n",
      "[79]\ttrain-rmse:1.96836\tval-rmse:1.96770\n",
      "[80]\ttrain-rmse:1.94977\tval-rmse:1.94913\n",
      "[81]\ttrain-rmse:1.93138\tval-rmse:1.93076\n",
      "[82]\ttrain-rmse:1.91318\tval-rmse:1.91259\n",
      "[83]\ttrain-rmse:1.89517\tval-rmse:1.89461\n",
      "[84]\ttrain-rmse:1.87736\tval-rmse:1.87680\n",
      "[85]\ttrain-rmse:1.85972\tval-rmse:1.85921\n",
      "[86]\ttrain-rmse:1.84228\tval-rmse:1.84180\n",
      "[87]\ttrain-rmse:1.82501\tval-rmse:1.82453\n",
      "[88]\ttrain-rmse:1.80793\tval-rmse:1.80746\n",
      "[89]\ttrain-rmse:1.79103\tval-rmse:1.79059\n",
      "[90]\ttrain-rmse:1.77431\tval-rmse:1.77389\n",
      "[91]\ttrain-rmse:1.75776\tval-rmse:1.75738\n",
      "[92]\ttrain-rmse:1.74139\tval-rmse:1.74102\n",
      "[93]\ttrain-rmse:1.72519\tval-rmse:1.72483\n",
      "[94]\ttrain-rmse:1.70917\tval-rmse:1.70881\n",
      "[95]\ttrain-rmse:1.69330\tval-rmse:1.69298\n",
      "[96]\ttrain-rmse:1.67761\tval-rmse:1.67731\n",
      "[97]\ttrain-rmse:1.66209\tval-rmse:1.66180\n",
      "[98]\ttrain-rmse:1.64674\tval-rmse:1.64647\n",
      "[99]\ttrain-rmse:1.63155\tval-rmse:1.63129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for eta in [0.3, 0.1, 0.01]:\n",
    "    params = {\n",
    "        'eta': eta,  # learning rate\n",
    "        'max_depth': 6,\n",
    "        'min_child_weight': 1,\n",
    "\n",
    "        'objective': 'reg:squarederror',\n",
    "        #'eval_metric': 'auc',\n",
    "        'nthread': 8,\n",
    "\n",
    "        'seed': 1,\n",
    "        'verbosity': 1,\n",
    "    }\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "    model = xgb.train(params, dtrain, evals=watchlist, verbose_eval=1, num_boost_round=100)\n",
    "\n",
    "    ypred = model.predict(dval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now change `eta` first to `0.1` and then to `0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"[0]\ttrain-rmse:3.02703\tval-rmse:3.02557\n",
    "[1]\ttrain-rmse:2.14613\tval-rmse:2.14509\n",
    "[2]\ttrain-rmse:1.53862\tval-rmse:1.53827\n",
    "[3]\ttrain-rmse:1.12540\tval-rmse:1.12612\n",
    "[4]\ttrain-rmse:0.85055\tval-rmse:0.85292\n",
    "[5]\ttrain-rmse:0.67431\tval-rmse:0.67813\n",
    "[6]\ttrain-rmse:0.56675\tval-rmse:0.57296\n",
    "[7]\ttrain-rmse:0.50401\tval-rmse:0.51231\n",
    "[8]\ttrain-rmse:0.46948\tval-rmse:0.47911\n",
    "[9]\ttrain-rmse:0.45044\tval-rmse:0.46159\n",
    "[10]\ttrain-rmse:0.43985\tval-rmse:0.45201\n",
    "[11]\ttrain-rmse:0.43278\tval-rmse:0.44717\n",
    "[12]\ttrain-rmse:0.42899\tval-rmse:0.44410\n",
    "[13]\ttrain-rmse:0.42636\tval-rmse:0.44219\n",
    "[14]\ttrain-rmse:0.42369\tval-rmse:0.44090\n",
    "[15]\ttrain-rmse:0.42215\tval-rmse:0.44048\n",
    "[16]\ttrain-rmse:0.42041\tval-rmse:0.44004\n",
    "[17]\ttrain-rmse:0.41946\tval-rmse:0.43961\n",
    "[18]\ttrain-rmse:0.41825\tval-rmse:0.43975\n",
    "[19]\ttrain-rmse:0.41627\tval-rmse:0.43923\n",
    "[20]\ttrain-rmse:0.41479\tval-rmse:0.43897\n",
    "[21]\ttrain-rmse:0.41335\tval-rmse:0.43922\n",
    "[22]\ttrain-rmse:0.41285\tval-rmse:0.43907\n",
    "[23]\ttrain-rmse:0.41216\tval-rmse:0.43909\n",
    "[24]\ttrain-rmse:0.41043\tval-rmse:0.43914\n",
    "[25]\ttrain-rmse:0.40974\tval-rmse:0.43915\n",
    "[26]\ttrain-rmse:0.40908\tval-rmse:0.43933\n",
    "[27]\ttrain-rmse:0.40780\tval-rmse:0.43920\n",
    "[28]\ttrain-rmse:0.40710\tval-rmse:0.43880\n",
    "[29]\ttrain-rmse:0.40663\tval-rmse:0.43867\n",
    "[30]\ttrain-rmse:0.40647\tval-rmse:0.43867\n",
    "[31]\ttrain-rmse:0.40625\tval-rmse:0.43862\n",
    "[32]\ttrain-rmse:0.40506\tval-rmse:0.43860\n",
    "[33]\ttrain-rmse:0.40418\tval-rmse:0.43856\n",
    "[34]\ttrain-rmse:0.40390\tval-rmse:0.43854\n",
    "[35]\ttrain-rmse:0.40271\tval-rmse:0.43817\n",
    "[36]\ttrain-rmse:0.40191\tval-rmse:0.43801\n",
    "[37]\ttrain-rmse:0.40094\tval-rmse:0.43770\n",
    "[38]\ttrain-rmse:0.40016\tval-rmse:0.43795\n",
    "[39]\ttrain-rmse:0.39924\tval-rmse:0.43740\n",
    "[40]\ttrain-rmse:0.39886\tval-rmse:0.43733\n",
    "[41]\ttrain-rmse:0.39768\tval-rmse:0.43693\n",
    "[42]\ttrain-rmse:0.39649\tval-rmse:0.43677\n",
    "[43]\ttrain-rmse:0.39549\tval-rmse:0.43687\n",
    "[44]\ttrain-rmse:0.39536\tval-rmse:0.43688\n",
    "[45]\ttrain-rmse:0.39484\tval-rmse:0.43699\n",
    "[46]\ttrain-rmse:0.39446\tval-rmse:0.43700\n",
    "[47]\ttrain-rmse:0.39404\tval-rmse:0.43695\n",
    "[48]\ttrain-rmse:0.39328\tval-rmse:0.43699\n",
    "[49]\ttrain-rmse:0.39300\tval-rmse:0.43728\n",
    "[50]\ttrain-rmse:0.39283\tval-rmse:0.43734\n",
    "[51]\ttrain-rmse:0.39277\tval-rmse:0.43736\n",
    "[52]\ttrain-rmse:0.39195\tval-rmse:0.43763\n",
    "[53]\ttrain-rmse:0.39171\tval-rmse:0.43758\n",
    "[54]\ttrain-rmse:0.39101\tval-rmse:0.43785\n",
    "[55]\ttrain-rmse:0.38981\tval-rmse:0.43765\n",
    "[56]\ttrain-rmse:0.38934\tval-rmse:0.43764\n",
    "[57]\ttrain-rmse:0.38916\tval-rmse:0.43766\n",
    "[58]\ttrain-rmse:0.38816\tval-rmse:0.43753\n",
    "[59]\ttrain-rmse:0.38787\tval-rmse:0.43742\n",
    "[60]\ttrain-rmse:0.38735\tval-rmse:0.43758\n",
    "[61]\ttrain-rmse:0.38702\tval-rmse:0.43768\n",
    "[62]\ttrain-rmse:0.38635\tval-rmse:0.43766\n",
    "[63]\ttrain-rmse:0.38546\tval-rmse:0.43742\n",
    "[64]\ttrain-rmse:0.38525\tval-rmse:0.43744\n",
    "[65]\ttrain-rmse:0.38445\tval-rmse:0.43733\n",
    "[66]\ttrain-rmse:0.38415\tval-rmse:0.43752\n",
    "[67]\ttrain-rmse:0.38398\tval-rmse:0.43756\n",
    "[68]\ttrain-rmse:0.38258\tval-rmse:0.43701\n",
    "[69]\ttrain-rmse:0.38208\tval-rmse:0.43717\n",
    "[70]\ttrain-rmse:0.38157\tval-rmse:0.43712\n",
    "[71]\ttrain-rmse:0.38150\tval-rmse:0.43711\n",
    "[72]\ttrain-rmse:0.38146\tval-rmse:0.43717\n",
    "[73]\ttrain-rmse:0.38121\tval-rmse:0.43725\n",
    "[74]\ttrain-rmse:0.38038\tval-rmse:0.43733\n",
    "[75]\ttrain-rmse:0.37956\tval-rmse:0.43737\n",
    "[76]\ttrain-rmse:0.37880\tval-rmse:0.43755\n",
    "[77]\ttrain-rmse:0.37777\tval-rmse:0.43764\n",
    "[78]\ttrain-rmse:0.37693\tval-rmse:0.43796\n",
    "[79]\ttrain-rmse:0.37614\tval-rmse:0.43794\n",
    "[80]\ttrain-rmse:0.37542\tval-rmse:0.43784\n",
    "[81]\ttrain-rmse:0.37514\tval-rmse:0.43781\n",
    "[82]\ttrain-rmse:0.37437\tval-rmse:0.43786\n",
    "[83]\ttrain-rmse:0.37412\tval-rmse:0.43790\n",
    "[84]\ttrain-rmse:0.37398\tval-rmse:0.43785\n",
    "[85]\ttrain-rmse:0.37362\tval-rmse:0.43782\n",
    "[86]\ttrain-rmse:0.37321\tval-rmse:0.43798\n",
    "[87]\ttrain-rmse:0.37269\tval-rmse:0.43788\n",
    "[88]\ttrain-rmse:0.37256\tval-rmse:0.43794\n",
    "[89]\ttrain-rmse:0.37165\tval-rmse:0.43790\n",
    "[90]\ttrain-rmse:0.37120\tval-rmse:0.43795\n",
    "[91]\ttrain-rmse:0.37055\tval-rmse:0.43788\n",
    "[92]\ttrain-rmse:0.37038\tval-rmse:0.43775\n",
    "[93]\ttrain-rmse:0.37022\tval-rmse:0.43776\n",
    "[94]\ttrain-rmse:0.36998\tval-rmse:0.43766\n",
    "[95]\ttrain-rmse:0.36976\tval-rmse:0.43761\n",
    "[96]\ttrain-rmse:0.36909\tval-rmse:0.43737\n",
    "[97]\ttrain-rmse:0.36835\tval-rmse:0.43735\n",
    "[98]\ttrain-rmse:0.36793\tval-rmse:0.43730\n",
    "[99]\ttrain-rmse:0.36756\tval-rmse:0.43724\n",
    "\n",
    "[0]\ttrain-rmse:3.87166\tval-rmse:3.87023\n",
    "[1]\ttrain-rmse:3.49100\tval-rmse:3.48943\n",
    "[2]\ttrain-rmse:3.14898\tval-rmse:3.14727\n",
    "[3]\ttrain-rmse:2.84180\tval-rmse:2.84019\n",
    "[4]\ttrain-rmse:2.56602\tval-rmse:2.56456\n",
    "[5]\ttrain-rmse:2.31855\tval-rmse:2.31741\n",
    "[6]\ttrain-rmse:2.09664\tval-rmse:2.09553\n",
    "[7]\ttrain-rmse:1.89783\tval-rmse:1.89687\n",
    "[8]\ttrain-rmse:1.71990\tval-rmse:1.71921\n",
    "[9]\ttrain-rmse:1.56081\tval-rmse:1.56028\n",
    "[10]\ttrain-rmse:1.41865\tval-rmse:1.41831\n",
    "[11]\ttrain-rmse:1.29195\tval-rmse:1.29177\n",
    "[12]\ttrain-rmse:1.17926\tval-rmse:1.17927\n",
    "[13]\ttrain-rmse:1.07931\tval-rmse:1.07974\n",
    "[14]\ttrain-rmse:0.99068\tval-rmse:0.99147\n",
    "[15]\ttrain-rmse:0.91253\tval-rmse:0.91363\n",
    "[16]\ttrain-rmse:0.84369\tval-rmse:0.84516\n",
    "[17]\ttrain-rmse:0.78345\tval-rmse:0.78538\n",
    "[18]\ttrain-rmse:0.73084\tval-rmse:0.73319\n",
    "[19]\ttrain-rmse:0.68483\tval-rmse:0.68791\n",
    "[20]\ttrain-rmse:0.64525\tval-rmse:0.64899\n",
    "[21]\ttrain-rmse:0.61100\tval-rmse:0.61536\n",
    "[22]\ttrain-rmse:0.58162\tval-rmse:0.58670\n",
    "[23]\ttrain-rmse:0.55669\tval-rmse:0.56236\n",
    "[24]\ttrain-rmse:0.53532\tval-rmse:0.54185\n",
    "[25]\ttrain-rmse:0.51724\tval-rmse:0.52463\n",
    "[26]\ttrain-rmse:0.50195\tval-rmse:0.51004\n",
    "[27]\ttrain-rmse:0.48925\tval-rmse:0.49796\n",
    "[28]\ttrain-rmse:0.47851\tval-rmse:0.48783\n",
    "[29]\ttrain-rmse:0.46938\tval-rmse:0.47915\n",
    "[30]\ttrain-rmse:0.46183\tval-rmse:0.47202\n",
    "[31]\ttrain-rmse:0.45567\tval-rmse:0.46622\n",
    "[32]\ttrain-rmse:0.45008\tval-rmse:0.46140\n",
    "[33]\ttrain-rmse:0.44560\tval-rmse:0.45746\n",
    "[34]\ttrain-rmse:0.44185\tval-rmse:0.45415\n",
    "[35]\ttrain-rmse:0.43875\tval-rmse:0.45146\n",
    "[36]\ttrain-rmse:0.43594\tval-rmse:0.44922\n",
    "[37]\ttrain-rmse:0.43373\tval-rmse:0.44716\n",
    "[38]\ttrain-rmse:0.43155\tval-rmse:0.44543\n",
    "[39]\ttrain-rmse:0.42993\tval-rmse:0.44417\n",
    "[40]\ttrain-rmse:0.42865\tval-rmse:0.44305\n",
    "[41]\ttrain-rmse:0.42715\tval-rmse:0.44224\n",
    "[42]\ttrain-rmse:0.42603\tval-rmse:0.44155\n",
    "[43]\ttrain-rmse:0.42480\tval-rmse:0.44076\n",
    "[44]\ttrain-rmse:0.42378\tval-rmse:0.43998\n",
    "[45]\ttrain-rmse:0.42274\tval-rmse:0.43932\n",
    "[46]\ttrain-rmse:0.42207\tval-rmse:0.43895\n",
    "[47]\ttrain-rmse:0.42114\tval-rmse:0.43849\n",
    "[48]\ttrain-rmse:0.42023\tval-rmse:0.43822\n",
    "[49]\ttrain-rmse:0.41967\tval-rmse:0.43790\n",
    "[50]\ttrain-rmse:0.41896\tval-rmse:0.43757\n",
    "[51]\ttrain-rmse:0.41844\tval-rmse:0.43732\n",
    "[52]\ttrain-rmse:0.41802\tval-rmse:0.43707\n",
    "[53]\ttrain-rmse:0.41760\tval-rmse:0.43693\n",
    "[54]\ttrain-rmse:0.41711\tval-rmse:0.43668\n",
    "[55]\ttrain-rmse:0.41676\tval-rmse:0.43645\n",
    "[56]\ttrain-rmse:0.41631\tval-rmse:0.43630\n",
    "[57]\ttrain-rmse:0.41590\tval-rmse:0.43622\n",
    "[58]\ttrain-rmse:0.41534\tval-rmse:0.43614\n",
    "[59]\ttrain-rmse:0.41505\tval-rmse:0.43609\n",
    "[60]\ttrain-rmse:0.41492\tval-rmse:0.43612\n",
    "[61]\ttrain-rmse:0.41439\tval-rmse:0.43614\n",
    "[62]\ttrain-rmse:0.41414\tval-rmse:0.43608\n",
    "[63]\ttrain-rmse:0.41373\tval-rmse:0.43587\n",
    "[64]\ttrain-rmse:0.41362\tval-rmse:0.43584\n",
    "[65]\ttrain-rmse:0.41329\tval-rmse:0.43574\n",
    "[66]\ttrain-rmse:0.41319\tval-rmse:0.43576\n",
    "[67]\ttrain-rmse:0.41265\tval-rmse:0.43563\n",
    "[68]\ttrain-rmse:0.41246\tval-rmse:0.43565\n",
    "[69]\ttrain-rmse:0.41205\tval-rmse:0.43562\n",
    "[70]\ttrain-rmse:0.41158\tval-rmse:0.43545\n",
    "[71]\ttrain-rmse:0.41140\tval-rmse:0.43545\n",
    "[72]\ttrain-rmse:0.41112\tval-rmse:0.43538\n",
    "[73]\ttrain-rmse:0.41075\tval-rmse:0.43537\n",
    "[74]\ttrain-rmse:0.41059\tval-rmse:0.43544\n",
    "[75]\ttrain-rmse:0.41018\tval-rmse:0.43533\n",
    "[76]\ttrain-rmse:0.40974\tval-rmse:0.43526\n",
    "[77]\ttrain-rmse:0.40949\tval-rmse:0.43524\n",
    "[78]\ttrain-rmse:0.40927\tval-rmse:0.43528\n",
    "[79]\ttrain-rmse:0.40894\tval-rmse:0.43514\n",
    "[80]\ttrain-rmse:0.40876\tval-rmse:0.43517\n",
    "[81]\ttrain-rmse:0.40854\tval-rmse:0.43511\n",
    "[82]\ttrain-rmse:0.40829\tval-rmse:0.43517\n",
    "[83]\ttrain-rmse:0.40783\tval-rmse:0.43495\n",
    "[84]\ttrain-rmse:0.40775\tval-rmse:0.43495\n",
    "[85]\ttrain-rmse:0.40747\tval-rmse:0.43483\n",
    "[86]\ttrain-rmse:0.40736\tval-rmse:0.43484\n",
    "[87]\ttrain-rmse:0.40715\tval-rmse:0.43475\n",
    "[88]\ttrain-rmse:0.40688\tval-rmse:0.43476\n",
    "[89]\ttrain-rmse:0.40661\tval-rmse:0.43477\n",
    "[90]\ttrain-rmse:0.40656\tval-rmse:0.43480\n",
    "[91]\ttrain-rmse:0.40613\tval-rmse:0.43480\n",
    "[92]\ttrain-rmse:0.40595\tval-rmse:0.43481\n",
    "[93]\ttrain-rmse:0.40585\tval-rmse:0.43473\n",
    "[94]\ttrain-rmse:0.40575\tval-rmse:0.43476\n",
    "[95]\ttrain-rmse:0.40556\tval-rmse:0.43481\n",
    "[96]\ttrain-rmse:0.40551\tval-rmse:0.43482\n",
    "[97]\ttrain-rmse:0.40532\tval-rmse:0.43474\n",
    "[98]\ttrain-rmse:0.40507\tval-rmse:0.43472\n",
    "[99]\ttrain-rmse:0.40467\tval-rmse:0.43459\n",
    "\n",
    "[0]\ttrain-rmse:4.25284\tval-rmse:4.25141\n",
    "\n",
    "[1]\ttrain-rmse:4.21088\tval-rmse:4.20945\n",
    "[2]\ttrain-rmse:4.16935\tval-rmse:4.16791\n",
    "[3]\ttrain-rmse:4.12824\tval-rmse:4.12680\n",
    "[4]\ttrain-rmse:4.08756\tval-rmse:4.08610\n",
    "[5]\ttrain-rmse:4.04727\tval-rmse:4.04582\n",
    "[6]\ttrain-rmse:4.00740\tval-rmse:4.00595\n",
    "[7]\ttrain-rmse:3.96793\tval-rmse:3.96648\n",
    "[8]\ttrain-rmse:3.92886\tval-rmse:3.92741\n",
    "[9]\ttrain-rmse:3.89019\tval-rmse:3.88874\n",
    "[10]\ttrain-rmse:3.85191\tval-rmse:3.85046\n",
    "[11]\ttrain-rmse:3.81401\tval-rmse:3.81256\n",
    "[12]\ttrain-rmse:3.77650\tval-rmse:3.77504\n",
    "[13]\ttrain-rmse:3.73938\tval-rmse:3.73791\n",
    "[14]\ttrain-rmse:3.70262\tval-rmse:3.70115\n",
    "[15]\ttrain-rmse:3.66624\tval-rmse:3.66475\n",
    "[16]\ttrain-rmse:3.63023\tval-rmse:3.62875\n",
    "[17]\ttrain-rmse:3.59458\tval-rmse:3.59310\n",
    "[18]\ttrain-rmse:3.55930\tval-rmse:3.55781\n",
    "[19]\ttrain-rmse:3.52437\tval-rmse:3.52289\n",
    "[20]\ttrain-rmse:3.48980\tval-rmse:3.48831\n",
    "[21]\ttrain-rmse:3.45558\tval-rmse:3.45408\n",
    "[22]\ttrain-rmse:3.42170\tval-rmse:3.42020\n",
    "[23]\ttrain-rmse:3.38817\tval-rmse:3.38667\n",
    "[24]\ttrain-rmse:3.35498\tval-rmse:3.35346\n",
    "[25]\ttrain-rmse:3.32213\tval-rmse:3.32060\n",
    "[26]\ttrain-rmse:3.28961\tval-rmse:3.28806\n",
    "[27]\ttrain-rmse:3.25743\tval-rmse:3.25588\n",
    "[28]\ttrain-rmse:3.22557\tval-rmse:3.22403\n",
    "[29]\ttrain-rmse:3.19404\tval-rmse:3.19249\n",
    "[30]\ttrain-rmse:3.16283\tval-rmse:3.16127\n",
    "[31]\ttrain-rmse:3.13193\tval-rmse:3.13036\n",
    "[32]\ttrain-rmse:3.10135\tval-rmse:3.09978\n",
    "[33]\ttrain-rmse:3.07108\tval-rmse:3.06950\n",
    "[34]\ttrain-rmse:3.04113\tval-rmse:3.03955\n",
    "[35]\ttrain-rmse:3.01147\tval-rmse:3.00991\n",
    "[36]\ttrain-rmse:2.98212\tval-rmse:2.98057\n",
    "[37]\ttrain-rmse:2.95307\tval-rmse:2.95153\n",
    "[38]\ttrain-rmse:2.92431\tval-rmse:2.92281\n",
    "[39]\ttrain-rmse:2.89586\tval-rmse:2.89437\n",
    "[40]\ttrain-rmse:2.86768\tval-rmse:2.86624\n",
    "[41]\ttrain-rmse:2.83981\tval-rmse:2.83837\n",
    "[42]\ttrain-rmse:2.81221\tval-rmse:2.81081\n",
    "[43]\ttrain-rmse:2.78490\tval-rmse:2.78351\n",
    "[44]\ttrain-rmse:2.75786\tval-rmse:2.75651\n",
    "[45]\ttrain-rmse:2.73110\tval-rmse:2.72979\n",
    "[46]\ttrain-rmse:2.70462\tval-rmse:2.70332\n",
    "[47]\ttrain-rmse:2.67841\tval-rmse:2.67713\n",
    "[48]\ttrain-rmse:2.65247\tval-rmse:2.65121\n",
    "[49]\ttrain-rmse:2.62679\tval-rmse:2.62555\n",
    "[50]\ttrain-rmse:2.60138\tval-rmse:2.60017\n",
    "[51]\ttrain-rmse:2.57623\tval-rmse:2.57503\n",
    "[52]\ttrain-rmse:2.55133\tval-rmse:2.55017\n",
    "[53]\ttrain-rmse:2.52670\tval-rmse:2.52555\n",
    "[54]\ttrain-rmse:2.50232\tval-rmse:2.50118\n",
    "[55]\ttrain-rmse:2.47819\tval-rmse:2.47707\n",
    "[56]\ttrain-rmse:2.45431\tval-rmse:2.45322\n",
    "[57]\ttrain-rmse:2.43067\tval-rmse:2.42960\n",
    "[58]\ttrain-rmse:2.40728\tval-rmse:2.40623\n",
    "[59]\ttrain-rmse:2.38413\tval-rmse:2.38309\n",
    "[60]\ttrain-rmse:2.36122\tval-rmse:2.36019\n",
    "[61]\ttrain-rmse:2.33854\tval-rmse:2.33753\n",
    "[62]\ttrain-rmse:2.31610\tval-rmse:2.31512\n",
    "[63]\ttrain-rmse:2.29389\tval-rmse:2.29293\n",
    "[64]\ttrain-rmse:2.27191\tval-rmse:2.27099\n",
    "[65]\ttrain-rmse:2.25016\tval-rmse:2.24925\n",
    "[66]\ttrain-rmse:2.22864\tval-rmse:2.22775\n",
    "[67]\ttrain-rmse:2.20734\tval-rmse:2.20647\n",
    "[68]\ttrain-rmse:2.18626\tval-rmse:2.18540\n",
    "[69]\ttrain-rmse:2.16539\tval-rmse:2.16456\n",
    "[70]\ttrain-rmse:2.14475\tval-rmse:2.14394\n",
    "[71]\ttrain-rmse:2.12432\tval-rmse:2.12353\n",
    "[72]\ttrain-rmse:2.10410\tval-rmse:2.10331\n",
    "[73]\ttrain-rmse:2.08409\tval-rmse:2.08332\n",
    "[74]\ttrain-rmse:2.06429\tval-rmse:2.06354\n",
    "[75]\ttrain-rmse:2.04470\tval-rmse:2.04397\n",
    "[76]\ttrain-rmse:2.02531\tval-rmse:2.02460\n",
    "[77]\ttrain-rmse:2.00613\tval-rmse:2.00543\n",
    "[78]\ttrain-rmse:1.98715\tval-rmse:1.98647\n",
    "[79]\ttrain-rmse:1.96836\tval-rmse:1.96770\n",
    "[80]\ttrain-rmse:1.94977\tval-rmse:1.94913\n",
    "[81]\ttrain-rmse:1.93138\tval-rmse:1.93076\n",
    "[82]\ttrain-rmse:1.91318\tval-rmse:1.91259\n",
    "[83]\ttrain-rmse:1.89517\tval-rmse:1.89461\n",
    "[84]\ttrain-rmse:1.87736\tval-rmse:1.87680\n",
    "[85]\ttrain-rmse:1.85972\tval-rmse:1.85921\n",
    "[86]\ttrain-rmse:1.84228\tval-rmse:1.84180\n",
    "[87]\ttrain-rmse:1.82501\tval-rmse:1.82453\n",
    "[88]\ttrain-rmse:1.80793\tval-rmse:1.80746\n",
    "[89]\ttrain-rmse:1.79103\tval-rmse:1.79059\n",
    "[90]\ttrain-rmse:1.77431\tval-rmse:1.77389\n",
    "[91]\ttrain-rmse:1.75776\tval-rmse:1.75738\n",
    "[92]\ttrain-rmse:1.74139\tval-rmse:1.74102\n",
    "[93]\ttrain-rmse:1.72519\tval-rmse:1.72483\n",
    "[94]\ttrain-rmse:1.70917\tval-rmse:1.70881\n",
    "[95]\ttrain-rmse:1.69330\tval-rmse:1.69298\n",
    "[96]\ttrain-rmse:1.67761\tval-rmse:1.67731\n",
    "[97]\ttrain-rmse:1.66209\tval-rmse:1.66180\n",
    "[98]\ttrain-rmse:1.64674\tval-rmse:1.64647\n",
    "[99]\ttrain-rmse:1.63155\tval-rmse:1.63129\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "results = re.findall('val-rmse:(.+)', s)\n",
    "results = list(map(float, results))\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.43677\n",
      "0.1 0.43459\n",
      "0.01 1.63129\n"
     ]
    }
   ],
   "source": [
    "print(\"0.3\", min(results[:100]))\n",
    "print(\"0.1\", min(results[100:200]))\n",
    "print(\"0.01\", min(results[200:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the best eta?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "\n",
    "Submit your results here: https://forms.gle/wQgFkYE6CtdDed4w8\n",
    "\n",
    "It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "\n",
    "\n",
    "## Deadline\n",
    "\n",
    "\n",
    "The deadline for submitting is 20 October 2021, 17:00 CET (Wednesday). After that, the form will be closed.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
